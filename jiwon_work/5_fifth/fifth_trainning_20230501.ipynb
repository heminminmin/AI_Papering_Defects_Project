{"cells":[{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1682903441785,"user":{"displayName":"장지원","userId":"12234758792184765955"},"user_tz":-540},"id":"a-XaKNvly16j"},"outputs":[],"source":["# from google.colab import drive\n","# drive.mount('/content/drive')\n","# !unzip \"/content/drive/MyDrive/open.zip\""]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":10817,"status":"ok","timestamp":1682903645709,"user":{"displayName":"장지원","userId":"12234758792184765955"},"user_tz":-540},"id":"3VLDdumLyx5L"},"outputs":[],"source":["import os\n","import sys\n","import numpy as np\n","from tqdm import tqdm\n","import tensorflow as tf\n","from PIL import ImageFile\n","from datetime import datetime\n","from tensorflow.keras.utils import to_categorical\n","\n","sys.path.append(os.path.join(os.getcwd(), os.path.pardir, 'functions'))\n","from get_tensor_through_imgs_fn_v2 import get_tensor_through_imgs_fn"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":827,"status":"ok","timestamp":1682903649416,"user":{"displayName":"장지원","userId":"12234758792184765955"},"user_tz":-540},"id":"3X750IKJyx5O"},"outputs":[],"source":["# ======== 학습 시킬 모든 이미지 파일들의 경로에 대한 리스트와 라벨 데이터 리스트 생성하기 ========\n","\n","# c:\\Users\\UserK\\Desktop\\hansol_J\\jiwon_work\\..\\..\\open\\train\n","TRAIN_FOLDER_PATH = os.path.join(os.getcwd(), os.pardir, os.pardir, 'open', 'train')\n","# TRAIN_FOLDER_PATH = '/content/train/'\n","# print('TRAIN_FOLDER_PATH : ', TRAIN_FOLDER_PATH)\n","\n","def get_train_image_paths_and_labels_fn():\n","\n","    defect_types = os.listdir(TRAIN_FOLDER_PATH)\n","    # print('defect_types :', defect_types)\n","\n","    labels = []\n","    train_image_paths = []\n","\n","    for defect_type in defect_types:\n","\n","        file_names = os.listdir(os.path.join(TRAIN_FOLDER_PATH, defect_type))\n","        # print('file_names: ', file_names)\n","\n","        for file_name in file_names:\n","            train_image_paths.append(os.path.join(TRAIN_FOLDER_PATH, defect_type, file_name))\n","            labels.append(defect_type)\n","\n","    return train_image_paths, labels\n","\n","train_image_paths, labels = get_train_image_paths_and_labels_fn()\n","\n","# [ 하자 유형에 대한 폴더명\\\\파일명.확장자, ... ]\n","# print('train_image_paths: ', train_image_paths)\n","\n","# [ 하자 유형에 대한 폴더명, ... ]\n","# print('labels :', labels)\n","\n","# =================================================================="]},{"cell_type":"code","execution_count":8,"metadata":{"id":"Q56v2QX_yx5P"},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 3457/3457 [01:19<00:00, 43.53it/s]\n"]},{"name":"stdout","output_type":"stream","text":["train_image_tensor.shape : (3457, 227, 227, 3)\n"]}],"source":["# ========= 교수님 코드 따라서 이미지 데이터를 가져오고 차원 변형하기 =========\n","\n","# 잘린 이미지에 대한 로드 여부 설정\n","ImageFile.LOAD_TRUNCATED_IMAGES = True\n","\n","RESIZED_WIDTH = 227\n","RESIZED_HEIGHT = 227\n","\n","train_image_tensor = get_tensor_through_imgs_fn(train_image_paths, RESIZED_WIDTH, RESIZED_HEIGHT)\n","print('train_image_tensor.shape :', train_image_tensor.shape)\n","\n","# ==========================================================================\n"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"rLdtt8Pmyx5Q"},"outputs":[{"name":"stdout","output_type":"stream","text":["encoding_labels.shape : (3457, 19)\n","Training data size: 3457\n"]},{"name":"stderr","output_type":"stream","text":["WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"]},{"name":"stdout","output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv2d (Conv2D)             (None, 55, 55, 96)        34944     \n","                                                                 \n"," batch_normalization (BatchN  (None, 55, 55, 96)       384       \n"," ormalization)                                                   \n","                                                                 \n"," max_pooling2d (MaxPooling2D  (None, 27, 27, 96)       0         \n"," )                                                               \n","                                                                 \n"," conv2d_1 (Conv2D)           (None, 27, 27, 256)       614656    \n","                                                                 \n"," batch_normalization_1 (Batc  (None, 27, 27, 256)      1024      \n"," hNormalization)                                                 \n","                                                                 \n"," max_pooling2d_1 (MaxPooling  (None, 13, 13, 256)      0         \n"," 2D)                                                             \n","                                                                 \n"," conv2d_2 (Conv2D)           (None, 13, 13, 384)       885120    \n","                                                                 \n"," batch_normalization_2 (Batc  (None, 13, 13, 384)      1536      \n"," hNormalization)                                                 \n","                                                                 \n"," conv2d_3 (Conv2D)           (None, 13, 13, 384)       1327488   \n","                                                                 \n"," batch_normalization_3 (Batc  (None, 13, 13, 384)      1536      \n"," hNormalization)                                                 \n","                                                                 \n"," conv2d_4 (Conv2D)           (None, 13, 13, 256)       884992    \n","                                                                 \n"," batch_normalization_4 (Batc  (None, 13, 13, 256)      1024      \n"," hNormalization)                                                 \n","                                                                 \n"," max_pooling2d_2 (MaxPooling  (None, 6, 6, 256)        0         \n"," 2D)                                                             \n","                                                                 \n"," flatten (Flatten)           (None, 9216)              0         \n","                                                                 \n"," dense (Dense)               (None, 4096)              37752832  \n","                                                                 \n"," dropout (Dropout)           (None, 4096)              0         \n","                                                                 \n"," dense_1 (Dense)             (None, 4096)              16781312  \n","                                                                 \n"," dropout_1 (Dropout)         (None, 4096)              0         \n","                                                                 \n"," dense_2 (Dense)             (None, 19)                77843     \n","                                                                 \n","=================================================================\n","Total params: 58,364,691\n","Trainable params: 58,361,939\n","Non-trainable params: 2,752\n","_________________________________________________________________\n","Epoch 1/50\n","108/108 [==============================] - 200s 1s/step - loss: 3.2192 - accuracy: 0.3356\n","Epoch 2/50\n","108/108 [==============================] - 180s 1s/step - loss: 1.9892 - accuracy: 0.4071\n","Epoch 3/50\n","108/108 [==============================] - 184s 2s/step - loss: 1.7260 - accuracy: 0.4546\n","Epoch 4/50\n","108/108 [==============================] - 180s 2s/step - loss: 1.5808 - accuracy: 0.4783\n","Epoch 5/50\n","108/108 [==============================] - 174s 1s/step - loss: 1.4456 - accuracy: 0.5177\n","Epoch 6/50\n","108/108 [==============================] - 182s 2s/step - loss: 1.3459 - accuracy: 0.5396\n","Epoch 7/50\n","108/108 [==============================] - 179s 2s/step - loss: 1.2585 - accuracy: 0.5671\n","Epoch 8/50\n","108/108 [==============================] - 175s 1s/step - loss: 1.1781 - accuracy: 0.5793\n","Epoch 9/50\n","108/108 [==============================] - 173s 1s/step - loss: 1.1068 - accuracy: 0.6128\n","Epoch 10/50\n","108/108 [==============================] - 176s 2s/step - loss: 1.0153 - accuracy: 0.6438\n","Epoch 11/50\n","108/108 [==============================] - 176s 1s/step - loss: 0.9324 - accuracy: 0.6675\n","Epoch 12/50\n","108/108 [==============================] - 176s 2s/step - loss: 0.8834 - accuracy: 0.6811\n","Epoch 13/50\n","108/108 [==============================] - 171s 1s/step - loss: 0.8218 - accuracy: 0.6994\n","Epoch 14/50\n","108/108 [==============================] - 178s 2s/step - loss: 0.7575 - accuracy: 0.7231\n","Epoch 15/50\n","108/108 [==============================] - 173s 1s/step - loss: 0.6888 - accuracy: 0.7517\n","Epoch 16/50\n","108/108 [==============================] - 171s 1s/step - loss: 0.6333 - accuracy: 0.7685\n","Epoch 17/50\n","108/108 [==============================] - 170s 1s/step - loss: 0.5897 - accuracy: 0.7781\n","Epoch 18/50\n","108/108 [==============================] - 170s 1s/step - loss: 0.5363 - accuracy: 0.7972\n","Epoch 19/50\n","108/108 [==============================] - 170s 1s/step - loss: 0.4655 - accuracy: 0.8319\n","Epoch 20/50\n","108/108 [==============================] - 170s 1s/step - loss: 0.4639 - accuracy: 0.8336\n","Epoch 21/50\n","108/108 [==============================] - 170s 1s/step - loss: 0.4083 - accuracy: 0.8545\n","Epoch 22/50\n","108/108 [==============================] - 170s 1s/step - loss: 0.3499 - accuracy: 0.8753\n","Epoch 23/50\n","108/108 [==============================] - 169s 1s/step - loss: 0.3397 - accuracy: 0.8793\n","Epoch 24/50\n","108/108 [==============================] - 170s 1s/step - loss: 0.3215 - accuracy: 0.8877\n","Epoch 25/50\n","108/108 [==============================] - 171s 1s/step - loss: 0.2776 - accuracy: 0.8999\n","Epoch 26/50\n","108/108 [==============================] - 170s 1s/step - loss: 0.2347 - accuracy: 0.9236\n","Epoch 27/50\n","108/108 [==============================] - 171s 1s/step - loss: 0.2206 - accuracy: 0.9251\n","Epoch 28/50\n","108/108 [==============================] - 177s 2s/step - loss: 0.1967 - accuracy: 0.9317\n","Epoch 29/50\n","108/108 [==============================] - 181s 2s/step - loss: 0.1699 - accuracy: 0.9470\n","Epoch 30/50\n","108/108 [==============================] - 177s 2s/step - loss: 0.1632 - accuracy: 0.9485\n","Epoch 31/50\n","108/108 [==============================] - 167s 1s/step - loss: 0.1578 - accuracy: 0.9499\n","Epoch 32/50\n","108/108 [==============================] - 172s 1s/step - loss: 0.1491 - accuracy: 0.9488\n","Epoch 33/50\n","108/108 [==============================] - 173s 1s/step - loss: 0.1417 - accuracy: 0.9523\n","Epoch 34/50\n","108/108 [==============================] - 171s 1s/step - loss: 0.1072 - accuracy: 0.9682\n","Epoch 35/50\n","108/108 [==============================] - 173s 1s/step - loss: 0.1068 - accuracy: 0.9659\n","Epoch 36/50\n","108/108 [==============================] - 183s 2s/step - loss: 0.1119 - accuracy: 0.9633\n","Epoch 37/50\n","108/108 [==============================] - 181s 2s/step - loss: 0.0968 - accuracy: 0.9696\n","Epoch 38/50\n","108/108 [==============================] - 172s 1s/step - loss: 0.0773 - accuracy: 0.9789\n","Epoch 39/50\n","108/108 [==============================] - 174s 1s/step - loss: 0.0802 - accuracy: 0.9740\n","Epoch 40/50\n","108/108 [==============================] - 172s 1s/step - loss: 0.0642 - accuracy: 0.9829\n","Epoch 41/50\n","108/108 [==============================] - 195s 2s/step - loss: 0.0677 - accuracy: 0.9780\n","Epoch 42/50\n","108/108 [==============================] - 196s 2s/step - loss: 0.0741 - accuracy: 0.9809\n","Epoch 43/50\n","108/108 [==============================] - 204s 2s/step - loss: 0.0663 - accuracy: 0.9803\n","Epoch 44/50\n","108/108 [==============================] - 204s 2s/step - loss: 0.0506 - accuracy: 0.9847\n","Epoch 45/50\n","108/108 [==============================] - 205s 2s/step - loss: 0.0491 - accuracy: 0.9852\n","Epoch 46/50\n","108/108 [==============================] - 181s 2s/step - loss: 0.0441 - accuracy: 0.9884\n","Epoch 47/50\n","108/108 [==============================] - 172s 1s/step - loss: 0.0458 - accuracy: 0.9881\n","Epoch 48/50\n","108/108 [==============================] - 171s 1s/step - loss: 0.0394 - accuracy: 0.9884\n","Epoch 49/50\n","108/108 [==============================] - 173s 1s/step - loss: 0.0452 - accuracy: 0.9878\n","Epoch 50/50\n","108/108 [==============================] - 196s 2s/step - loss: 0.0308 - accuracy: 0.9916\n"]}],"source":["# ========================== Alexnet 코드 따라서 학습시키기 ==========================\n","# https://towardsdatascience.com/implementing-alexnet-cnn-architecture-using-tensorflow-2-0-and-keras-2113e090ad98\n","\n","EPOCHS = 50\n","\n","# ====================== 라벨 정규화 과정 ======================\n","\n","# 문자열 형태의 범주형 데이터인 라벨 데이터를 정수 형태로 정규화\n","normalized_labels = []\n","\n","# 추후에 라벨이 추가될 경우 등 확장성 및 모델의 안정성을 고려하여 총 19가지의 하자 유형의 순서가 변경되지 않도록 직접적으로 리스트 생성\n","DEFECT_TYPE_NAMES = [\"가구수정\", \"걸레받이수정\", \"곰팡이\", \"꼬임\", \"녹오염\", \"들뜸\", \"면불량\", \"몰딩수정\", \"반점\", \"석고수정\",\n","                     \"오염\", \"오타공\", \"울음\", \"이음부불량\", \"창틀,문틀수정\", \"터짐\", \"틈새과다\", \"피스\", \"훼손\"]\n","\n","defect_type_count = len(DEFECT_TYPE_NAMES)\n","\n","for label in labels:\n","    normalized_labels.append(DEFECT_TYPE_NAMES.index(label))\n","\n","# [ 0, 0, 0, ... ]\n","# print('normalized_labels :', normalized_labels)\n","\n","# 정수형 클래스의 레이블을 이진 클래스의 원핫 인코딩 벡터로 변환\n","encoding_labels = to_categorical(normalized_labels, defect_type_count)\n","print('encoding_labels.shape :', encoding_labels.shape)\n","\n","# =============================================================\n","\n","train_ds = tf.data.Dataset.from_tensor_slices(\n","    (train_image_tensor, encoding_labels))\n","\n","train_ds_size = tf.data.experimental.cardinality(train_ds).numpy()\n","print(\"Training data size:\", train_ds_size)\n","\n","train_ds = (train_ds\n","            .shuffle(buffer_size=train_ds_size)\n","            .batch(batch_size=32, drop_remainder=True))\n","\n","model = tf.keras.models.Sequential([\n","    tf.keras.layers.Conv2D(filters=96, kernel_size=(11, 11), strides=(\n","        4, 4), activation='relu', input_shape=(RESIZED_WIDTH, RESIZED_HEIGHT, 3)),\n","    tf.keras.layers.BatchNormalization(),\n","    tf.keras.layers.MaxPool2D(pool_size=(3, 3), strides=(2, 2)),\n","    tf.keras.layers.Conv2D(filters=256, kernel_size=(\n","        5, 5), strides=(1, 1), activation='relu', padding=\"same\"),\n","    tf.keras.layers.BatchNormalization(),\n","    tf.keras.layers.MaxPool2D(pool_size=(3, 3), strides=(2, 2)),\n","    tf.keras.layers.Conv2D(filters=384, kernel_size=(\n","        3, 3), strides=(1, 1), activation='relu', padding=\"same\"),\n","    tf.keras.layers.BatchNormalization(),\n","    tf.keras.layers.Conv2D(filters=384, kernel_size=(\n","        3, 3), strides=(1, 1), activation='relu', padding=\"same\"),\n","    tf.keras.layers.BatchNormalization(),\n","    tf.keras.layers.Conv2D(filters=256, kernel_size=(\n","        3, 3), strides=(1, 1), activation='relu', padding=\"same\"),\n","    tf.keras.layers.BatchNormalization(),\n","    tf.keras.layers.MaxPool2D(pool_size=(3, 3), strides=(2, 2)),\n","    tf.keras.layers.Flatten(),\n","    tf.keras.layers.Dense(4096, activation='relu'),\n","    tf.keras.layers.Dropout(0.5),\n","    tf.keras.layers.Dense(4096, activation='relu'),\n","    tf.keras.layers.Dropout(0.5),\n","    tf.keras.layers.Dense(19, activation='softmax')\n","])\n","\n","model.compile(loss='categorical_crossentropy',\n","              optimizer=tf.optimizers.SGD(learning_rate=0.001), metrics=['accuracy'])\n","\n","model.summary()\n","\n","model.fit(train_ds,\n","          epochs=EPOCHS)\n","\n","# 연월일_시간\n","now = datetime.today().strftime('%Y%m%d_%H%M%S')\n","model.save(f'model_{now}.h5')\n","\n","# ===================================================================================\n"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.10"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":0}
